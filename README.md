# new_repo_ai_powered
# AI-Powered Disk Analyzer

A production-ready, fully local AI system for intelligent file management, semantic search, and content organization.

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

## ğŸŒŸ Features

### Core Capabilities
- **ğŸ” Semantic Search**: Natural language queries across all documents and images
- **ğŸ–¼ï¸ Visual Search**: Find images by content, similarity, or upload reference images
- **ğŸ‘¤ Face Recognition**: Search for people across your photo library
- **ğŸ¯ Object Detection**: Find images containing specific objects
- **ğŸ“Š Smart Organization**: Automatic file clustering based on content similarity
- **ğŸ”„ Duplicate Detection**: Find exact and near-duplicate files
- **ğŸ’¡ AI Insights**: Summarization, keyword extraction, and Q&A
- **âš¡ Real-time Monitoring**: Automatic indexing of new/modified files

### Privacy First
- âœ… 100% local processing
- âœ… No cloud API calls
- âœ… All data stays on your device
- âœ… No telemetry or tracking

## ğŸ—ï¸ Architecture

### Technology Stack
- **Backend**: Python, LangChain, LangGraph
- **Vector Stores**: ChromaDB, FAISS
- **Models**:
  - Text: BGE-M3 (1024-dim embeddings)
  - Images: SigLIP (768-dim embeddings)
  - Faces: RetinaFace + ArcFace
  - Objects: YOLOv8
  - LLM: Mistral-7B (local inference)
- **Frontend**: Streamlit (multipage app)
- **OCR**: Tesseract + EasyOCR

### Pipeline Architecture
The system uses two main LangGraph pipelines:

1. **Ingestion Pipeline**: Processes files, extracts content, generates embeddings
2. **Query Pipeline**: Handles searches with multimodal support and intelligent routing

## ğŸ“¦ Installation

### Prerequisites
- Python 3.10 or higher
- 16GB RAM (minimum)
- 50GB free disk space (for models)
- GPU recommended but not required

### Quick Start
```bash
# Clone repository
git clone <repository-url>
cd ai-disk-analyzer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your preferences

# Download models
python scripts/download_models.py

# Initialize databases
python scripts/setup_database.py
source venv/Scripts/activate
# Run application
streamlit run frontend/app.py
python -m streamlit run frontend/app.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸš€ Usage

### Indexing Files

1. Open the app and go to the home page
2. Enter a folder path in "Index New Folder"
3. Click "Start Indexing"
4. Wait for processing to complete

### Searching

**Text Search:**
```
"Find my tax documents from 2023"
"Show me presentations about machine learning"
```

**Image Search:**
```
"Find photos of beaches"
"Show me images with cars"
```

**Face Search:**
- Upload a reference face image
- System finds all images with that person

### Organization

- View automatic file clusters
- Find and manage duplicates
- Get insights and statistics

## ğŸ“ Project Structure
```
ai-disk-analyzer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”œâ”€â”€ ingestion/           # File scanning and monitoring
â”‚   â”œâ”€â”€ processors/          # Text, image, OCR processors
â”‚   â”œâ”€â”€ embeddings/          # Embedding generation
â”‚   â”œâ”€â”€ detection/           # Face and object detection
â”‚   â”œâ”€â”€ vectorstore/         # Vector database operations
â”‚   â”œâ”€â”€ orchestration/       # LangGraph pipelines
â”‚   â”œâ”€â”€ search/              # Search implementations
â”‚   â”œâ”€â”€ llm/                 # LLM integration
â”‚   â”œâ”€â”€ analysis/            # Clustering and insights
â”‚   â””â”€â”€ utils/               # Utilities
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py               # Main Streamlit app
â”‚   â””â”€â”€ pages/               # Multipage components
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vector_stores/       # Vector databases
â”‚   â”œâ”€â”€ models/              # Downloaded models
â”‚   â””â”€â”€ logs/                # Application logs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_models.py   # Model downloader
â”‚   â”œâ”€â”€ setup_database.py    # DB initialization
â”‚   â””â”€â”€ benchmark.py         # Performance testing
â””â”€â”€ requirements.txt
```

## ğŸ”§ Configuration

Edit `.env` to customize:
```bash
# Model settings
BGE_MODEL_PATH=BAAI/bge-m3
ENABLE_GPU=true

# Processing
BATCH_SIZE=32
MAX_FILE_SIZE_MB=100

# Search
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.6
```

## ğŸ“Š Performance

Benchmark your system:
```bash
python scripts/benchmark.py
```

**Expected Performance** (with GPU):
- Text embedding: ~50 texts/sec
- Image embedding: ~10 images/sec
- Vector search: ~100 searches/sec

## ğŸ› Troubleshooting

### Common Issues

**Out of Memory:**
- Reduce `BATCH_SIZE` in `.env`
- Enable GPU if available
- Process files in smaller batches

**Slow Processing:**
- Ensure GPU is enabled
- Check `ENABLE_GPU=true` in `.env`
- Reduce model sizes if needed

**Models Not Found:**
- Run `python scripts/download_models.py` again
- Check internet connection
- Verify HuggingFace access

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- LangChain & LangGraph for orchestration
- HuggingFace for model hosting
- Streamlit for the frontend framework
- All open-source contributors

## ğŸ“ Support

For issues and questions:
- GitHub Issues: [Create an issue]
- Documentation: [Read the docs]

---

**Made with â¤ï¸ for privacy-conscious AI enthusiasts**